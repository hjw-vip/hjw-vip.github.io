---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
# Hi, welcome to my homepage! ğŸ‘‹

I'm **Samuel Hu** (CN name: **èƒ¡å³»ç®**), a third-year undergraduate student majoring in **Software Engineering** at the **School of Computer Science and Technology** (School of Software Engineering), **Tongji University**. 

During my time at Tongji, I have participated in several research projects. I worked on a project led by Lecturer [**Tang Jianfeng**](https://cs.tongji.edu.cn/info/1064/2776.htm) at Tongji University, which focused on the diffusion mechanism of user interests on recommendation algorithm platforms. I have also been involved in Professor [**Ye**](https://cs.tongji.edu.cn/info/1122/3256.htm)'s lab at Tongji University, conducting research on AI-based Chinese character visualization technology. Additionally, I am currently part of Associate Professor [**Dong**](https://math.tongji.edu.cn/info/1255/9703.htm)'s research group, where I am exploring the application of reinforcement learning in financial investments. Meanwhile, I am currently working in Associate Professor [**Yan Liu**](https://cs.tongji.edu.cn/info/1063/2763.htm)'s lab, focusing on large code models and AI4SE.

## Research Areas ğŸ“š

My main research areas include:

- **LLM4code**  
- **AI4SE**  
- **SE4AI**  
- **NLP**  
- **Data Analysis**  
- And more...  

If you are interested in these research topics, feel free to email me at [**Samuel Hu's Email**](mailto:m15844917507_1@163.com) ğŸ“§

Looking forward to connecting! ğŸ˜Š


# ğŸ”¥ News
- *2025.03*: ğŸ¥‡ **æ ¡çº§ä¸€ç­‰å¥–** - åŒæµå¤§å­¦ç¬¬åå±Šâ€œå“è¶Šæ¯â€æš¨ç¬¬åä¹å±Šâ€œæŒ‘æˆ˜æ¯â€å…¨å›½å¤§å­¦ç”Ÿè¯¾å¤–å­¦æœ¯ç§‘æŠ€ä½œå“ç«èµ›
- *2024.12*: ğŸ–ï¸ **å›½å®¶å¥–å­¦é‡‘** - 2023-2024å­¦å¹´åº¦
- *2024.12*: ğŸ–ï¸ **ä¼˜ç§€å­¦ç”Ÿ (5%)** - 2023-2024å­¦å¹´åº¦
- *2024.12*: ğŸ† **åˆ›æ–°åº”ç”¨å¥– (4/58)** - ä¸­å›½é«˜æ ¡è®¡ç®—æœºå¤§èµ›â€”â€”äººå·¥æ™ºèƒ½åˆ›æ„èµ›å…¨å›½æ€»å†³èµ›
- *2024.12*: ğŸ¥‰ **å…¨å›½ä¸‰ç­‰å¥–** - ç¬¬å…­å±Šå…¨çƒæ ¡å›­äººå·¥æ™ºèƒ½ç®—æ³•ç²¾è‹±å¤§èµ›å…¨å›½æ€»å†³èµ›
- *2024.12*: ğŸ¥‰ **å…¨å›½ä¸‰ç­‰å¥–** - ä¸­å›½é«˜æ ¡è®¡ç®—æœºå¤§èµ›â€”â€”äººå·¥æ™ºèƒ½åˆ›æ„èµ›å…¨å›½æ€»å†³èµ›
- *2024.12*: ğŸ¥ˆ **çœçº§äºŒç­‰å¥–** - 024å¹´é«˜æ•™ç¤¾æ¯å…¨å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ›
- *2024.12*: ğŸ¥‰ **çœçº§ä¸‰ç­‰å¥–** - ç¬¬åå…­å±Šå…¨å›½å¤§å­¦ç”Ÿæ•°å­¦ç«èµ›ï¼ˆéæ•°å­¦ç±»ï¼‰
- *2024.12*: ğŸ¥‰ **å¸‚çº§ä¸‰ç­‰å¥–** - ç¬¬åå…­å±Šä¸Šæµ·å¸‚å¤§å­¦ç”Ÿæ•°å­¦ç«èµ›ï¼ˆéæ•°å­¦ç±»ï¼‰

# ğŸ“ Publications 

<div class='paper-box'>
  <div class='paper-box-image'>
    <div>
      <div class="badge">arXiv Preprint 2025</div>
      <img src='images/CodingFlow_01.png' alt="sym" width="100%">
    </div>
  </div>
  <div class='paper-box-text' markdown="1">
    [Token-Aware Coding Flow: A Study with Nano Surge in Reasoning Model](https://arxiv.org/abs/2504.15989)

    **Junwei Hu**, Weicheng Zheng, Yihan Liu, Yan Liu

    - This paper explores the impact of code smells on token consumption during model inference in large language models (LLMs) and introduces the "Token-Aware Coding Flow" method. We show that code refactoring and prompt engineering strategies can significantly reduce token consumption, improving reasoning efficiency and code generation quality.
  </div>
</div>


# ğŸ– Honors and Awards
- *2025.03*: ğŸ¥‡ **æ ¡çº§ä¸€ç­‰å¥–** - åŒæµå¤§å­¦ç¬¬åå±Šâ€œå“è¶Šæ¯â€æš¨ç¬¬åä¹å±Šâ€œæŒ‘æˆ˜æ¯â€å…¨å›½å¤§å­¦ç”Ÿè¯¾å¤–å­¦æœ¯ç§‘æŠ€ä½œå“ç«èµ›
- *2024.12*: ğŸ–ï¸ **å›½å®¶å¥–å­¦é‡‘** - 2023-2024å­¦å¹´åº¦
- *2024.12*: ğŸ–ï¸ **ä¼˜ç§€å­¦ç”Ÿ (5%)** - 2023-2024å­¦å¹´åº¦
- *2024.12*: ğŸ† **åˆ›æ–°åº”ç”¨å¥– (4/58)** - ä¸­å›½é«˜æ ¡è®¡ç®—æœºå¤§èµ›â€”â€”äººå·¥æ™ºèƒ½åˆ›æ„èµ›å…¨å›½æ€»å†³èµ›
- *2024.12*: ğŸ¥‰ **å…¨å›½ä¸‰ç­‰å¥–** - ç¬¬å…­å±Šå…¨çƒæ ¡å›­äººå·¥æ™ºèƒ½ç®—æ³•ç²¾è‹±å¤§èµ›å…¨å›½æ€»å†³èµ›
- *2024.12*: ğŸ¥‰ **å…¨å›½ä¸‰ç­‰å¥–** - ä¸­å›½é«˜æ ¡è®¡ç®—æœºå¤§èµ›â€”â€”äººå·¥æ™ºèƒ½åˆ›æ„èµ›å…¨å›½æ€»å†³èµ›
- *2024.12*: ğŸ¥ˆ **çœçº§äºŒç­‰å¥–** - 024å¹´é«˜æ•™ç¤¾æ¯å…¨å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ›
- *2024.12*: ğŸ¥‰ **çœçº§ä¸‰ç­‰å¥–** - ç¬¬åå…­å±Šå…¨å›½å¤§å­¦ç”Ÿæ•°å­¦ç«èµ›ï¼ˆéæ•°å­¦ç±»ï¼‰
- *2024.12*: ğŸ¥‰ **å¸‚çº§ä¸‰ç­‰å¥–** - ç¬¬åå…­å±Šä¸Šæµ·å¸‚å¤§å­¦ç”Ÿæ•°å­¦ç«èµ›ï¼ˆéæ•°å­¦ç±»ï¼‰
- *2024.11*: ğŸ¥‡ **åŒºåŸŸä¸€ç­‰å¥–** - ç¬¬å…­å±Šå…¨çƒæ ¡å›­äººå·¥æ™ºèƒ½ç®—æ³•ç²¾è‹±å¤§èµ›
- *2024.10*: ğŸ¥ˆ **åŒºåŸŸäºŒç­‰å¥–** - ä¸­å›½é«˜æ ¡è®¡ç®—æœºå¤§èµ›â€”â€”äººå·¥æ™ºèƒ½åˆ›æ„èµ›
- *2024.09*: ğŸ¥‡ **æ ¡çº§ä¸€ç­‰å¥–** - 2024åŒæµå¤§å­¦ç»Ÿè®¡å»ºæ¨¡å¤§èµ›
- *2024.07*: ğŸ¥‡ **å…¨å›½ä¸€ç­‰å¥–** - ç¬¬äºŒåå…­å±Šä¸­å›½æœºå™¨äººåŠäººå·¥æ™ºèƒ½å¤§èµ›å…¨å›½æ€»å†³èµ›
- *2024.07*: ğŸ¥ˆ **å…¨å›½äºŒç­‰å¥–** - ä¸­å›½é«˜æ ¡è®¡ç®—æœºå¤§èµ›â€”â€”AIGCåˆ›æ–°èµ›å…¨å›½æ€»å†³èµ›
- *2024.07*: ğŸ—ï¸ **å¤èµ›å…¥å›´** - ä¸­å›½é«˜æ ¡è®¡ç®—æœºå¤§èµ›â€”â€”æ™ºèƒ½äº¤äº’åˆ›æ–°èµ›
- *2024.06*: ğŸ¥‡ **çœçº§ä¸€ç­‰å¥–** - ç¬¬äºŒåå…­å±Šä¸­å›½æœºå™¨äººåŠäººå·¥æ™ºèƒ½å¤§èµ›
- *2024.06*: ğŸ¥‡ **æ ¡çº§é‡‘å¥–** - ç¬¬ä¹å±Šä¸­å›½å›½é™…â€œäº’è”ç½‘+â€å¤§å­¦ç”Ÿåˆ›æ–°åˆ›ä¸šå¤§èµ›åŒæµæ ¡å†…èµ›
- *2024.06*: ğŸ¥‡ **æ ¡çº§é‡‘å¥–** - ä¸­å›½å›½é™…å¤§å­¦ç”Ÿåˆ›æ–°å¤§èµ›ï¼ˆæ ¡èµ›ï¼‰
- *2024.06*: ğŸ¥‰ **æˆåŠŸå‚ä¸å¥–** - ç¾å›½å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ›
- *2024.04*: ğŸ—ï¸ **ç»“é¢˜** - å›½å®¶çº§åˆ›æ–°åˆ›ä¸šé¡¹ç›®â€”â€”â€œå½¢ç¥å…¼å¤‡â€çš„æ¥·ä¹¦è¾…åŠ©è¯„ä»·ç³»ç»Ÿ
- *2023.12*: ğŸ¥ˆ **æ ¡çº§äºŒç­‰å¥–** - ç¬¬ä¹å±ŠåŒæµå¤§å­¦â€œä½¿å‘½ä¸æ‹…å½“â€ç«èµ›å†³èµ›
- *2023.08*: ğŸ¥ˆ **çœçº§äºŒç­‰å¥–** - ç¬¬å…«å±Šâ€œæ±‡åˆ›é’æ˜¥â€ä¸Šæµ·å¤§å­¦ç”Ÿæ–‡åŒ–åˆ›æ„ä½œå“å±•ç¤ºæ´»åŠ¨
- *2023.06*: ğŸ¥‡ **æ ¡çº§é‡‘å¥–** - ç¬¬ä¹å±Šä¸­å›½å›½é™…â€œäº’è”ç½‘+â€å¤§å­¦ç”Ÿåˆ›æ–°åˆ›ä¸šå¤§èµ›åŒæµæ ¡å†…èµ›
- *2023.04*: ğŸ—ï¸ **ç»“é¢˜** - æ ¡çº§åˆ›åˆ›æ–°åˆ›ä¸šé¡¹ç›®â€”â€”åœŸæœ¨å·¥ç¨‹è®¡ç®—æœºè§†è§‰ä¸æ·±åº¦å­¦ä¹ å…±äº«ç¤¾åŒº
- *2023.01*: ğŸ¥‰ **çœçº§ä¸‰ç­‰å¥–** - ç¬¬åå››å±Šå…¨å›½å¤§å­¦ç”Ÿæ•°å­¦ç«èµ›ï¼ˆéæ•°å­¦ç±»ï¼‰
- *2022.12*: ğŸ–ï¸ **æ ¡çº§ä¼˜ç§€å­¦ç”Ÿä¸‰ç­‰å¥–å­¦é‡‘** - 2021-2022å­¦å¹´åº¦
- *2022.12*: ğŸ¥‰ **å¸‚çº§ä¸‰ç­‰å¥–** - ç¬¬åå››å±Šä¸Šæµ·å¸‚å¤§å­¦ç”Ÿæ•°å­¦ç«èµ›ï¼ˆéæ•°å­¦ç±»ï¼‰
- *2022.12*: ğŸ—ï¸ **å¤èµ›å…¥å›´** - ç¬¬ä¹å±ŠåŒæµå¤§å­¦â€œä½¿å‘½ä¸æ‹…å½“â€ç«èµ›

# ğŸ“– Educations
- *2022.09 - 2026.06 (now)*, **Bachelor's Degree in Software Engineering**, School of Computer Science and Technology, Tongji University, Shanghai, China.

# ğŸ’» Research experience
- *2024.10 - Present*, [Research on Large Code Models and AI4SE](https://cs.tongji.edu.cn/info/1063/2763.htm), Associate Professor [**Yan Liu**](https://cs.tongji.edu.cn/info/1063/2763.htm), Tongji University, China.
- *2024.06 - 2024.08*, [Diffusion Mechanism of User Interests on Recommendation Algorithm Platforms](https://cs.tongji.edu.cn/info/1064/2776.htm), Lecturer [**Tang Jianfeng**](https://cs.tongji.edu.cn/info/1064/2776.htm), Tongji University, China.
- *2023.04 - 2024.04*, [Reinforcement Learning in Financial Investments](https://math.tongji.edu.cn/info/1255/9703.htm), Associate Professor [**Dong**](https://math.tongji.edu.cn/info/1255/9703.htm), Tongji University, China.
- *2022.04 - 2024.9*, [AI-Based Chinese Character Visualization](https://cs.tongji.edu.cn/info/1122/3256.htm), Professor [**Ye**](https://cs.tongji.edu.cn/info/1122/3256.htm), Tongji University, China.

